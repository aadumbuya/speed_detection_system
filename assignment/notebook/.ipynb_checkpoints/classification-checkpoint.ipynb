{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09bb383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from joblib import dump,load\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d95ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(name,sep=\",\"):\n",
    "    data = pd.read_csv(name,sep=sep)\n",
    "    return data\n",
    "\n",
    "def read_from_file(typ_,name,sep=None):\n",
    "    if typ_ == \"csv\":\n",
    "        data = read_csv(name,sep)\n",
    "    else:\n",
    "        data = None\n",
    "    return data\n",
    "    \n",
    "def read_from_data(typ_,data):\n",
    "    return None   \n",
    "\n",
    "def read_from_file_or_data(typ_,sect=None,name=None,data=None,sep=None):\n",
    "    if sect == \"file\":\n",
    "        data = read_from_file(typ_,name,sep)\n",
    "    else:\n",
    "        data = read_from_data(typ_,data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb53d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframe_csv(dataframe,name):\n",
    "    dataframe.to_csv(name)\n",
    "    \n",
    "def write_data(typ_,data,name):\n",
    "    if typ_ == \"csv\":\n",
    "        write_dataframe_csv(data,name)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8dfffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_one(data):\n",
    "    return data\n",
    "\n",
    "def load_two(data1,data2,axis=0,drop_index=True):\n",
    "    combined = pd.concat([data1,data2],axis=axis)\n",
    "    combined = combined.sample(frac=1,random_state=2).reset_index(drop=drop_index)\n",
    "    return combined\n",
    "\n",
    "def loader(typ_,data,axis=0,drop_index=True):\n",
    "    if typ_ == \"one\":\n",
    "        data = load_one(data)\n",
    "    elif typ_ == \"two\":\n",
    "        data = load_two(data[0],data[1],axis=0,drop_index=True)\n",
    "    else:\n",
    "        data = None\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070e73bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_spliter(train,label,random_state=2,test_size=0.3):\n",
    "    train_x,test_x,train_y,test_y = train_test_split(train,label,random_state=random_state,test_size=test_size)\n",
    "    return train_x,test_x,train_y,test_y\n",
    "\n",
    "def set_ss(data):\n",
    "    ss = StandardScaler()\n",
    "    scaled = ss.fit_transform(data)\n",
    "    return scaled\n",
    "\n",
    "def scalers(typ_,data):\n",
    "    scaled = None\n",
    "    if typ_ == \"ss\":\n",
    "        scaled = set_ss(data)\n",
    "    else:\n",
    "        pass\n",
    "    return scaled\n",
    "\n",
    "\n",
    "def select_train_columns(data,n):\n",
    "    train = data.iloc[:,:n]\n",
    "    return train,train.columns\n",
    "    \n",
    "def select_label_column(data,column_name):\n",
    "    labels = np.array(data[column_name])\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a88103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcl_train(train,label,model_name):\n",
    "    dcl = DecisionTreeClassifier()\n",
    "    dcl.fit(train,label)\n",
    "    dump(dcl,model_name) \n",
    "    return dcl\n",
    "\n",
    "def train(typ_,train,label,model_name):\n",
    "    if typ_ == \"dcl\":\n",
    "        return dcl_train(train,label,model_name)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c1cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_name,data):\n",
    "    model = load(model_name) \n",
    "    label = model.predict(data)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d9eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_with_new_data(model_name,train,label):\n",
    "    model = load(model_name)\n",
    "    model.fit(train,label)\n",
    "    dump(model,model_name) \n",
    "    return model\n",
    "    \n",
    "    \n",
    "def retrain_with_new_and_old_data(model_name,train,label):\n",
    "    c_train = np.vstack([train[0], train[1]])\n",
    "    clabel = np.concatenate([label[0], label[1]])\n",
    "    model = load(model_name)\n",
    "    model.fit(c_train,clabel)\n",
    "    dump(model,model_name)\n",
    "    return model\n",
    "    \n",
    "def retrain(typ_,model_name,train,label):\n",
    "    if typ_ == \"only_new\":\n",
    "        model = retrain_with_new_data(model_name,train,label)\n",
    "    elif typ_ == \"new_and_old\":\n",
    "        model = retrain_with_new_and_old_data(model_name,train,label)\n",
    "    else:\n",
    "        pass\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d949cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(true_labels, predicted_labels):\n",
    "    metrics = {}\n",
    "    \n",
    "    metrics['Accuracy:'] = np.round(metrics.accuracy_score(true_labels,predicted_labels),4)\n",
    "    metrics['Precision:'] =  np.round(metrics.precision_score(true_labels,predicted_labels,average='weighted'),4)\n",
    "    metrics['Recall:'] = np.round(metrics.recall_score(true_labels,predicted_labels,average='weighted'),4)\n",
    "    metrics['F1 Score:'] = np.round(metrics.f1_score(true_labels,predicted_labels,average='weighted'),4)\n",
    "    return metrics\n",
    "\n",
    "def display_classification_report(true_labels, predicted_labels, classes=[1,0]):\n",
    "\n",
    "    report = metrics.classification_report(y_true=true_labels, \n",
    "                                           y_pred=predicted_labels, \n",
    "                                           labels=classes) \n",
    "    return report\n",
    "    \n",
    "    \n",
    "    \n",
    "def display_model_performance_metrics(true_labels, predicted_labels, classes=[1,0]):\n",
    "    stats = {}\n",
    "    metrics = get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n",
    "    report = display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels,classes=classes)\n",
    "    stats[\"metrics\"] = metrics\n",
    "    stats[\"report\"] = report\n",
    "    return stats\n",
    "\n",
    "def model_analysis(true_labels,predicted_labels,classes,typ_=\"default\"):\n",
    "    if typ_ == \"default\":\n",
    "        metrics = display_model_performance_metrics(true_labels, predicted_labels,classes)\n",
    "    else:\n",
    "        pass\n",
    "    return metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71415947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(data):\n",
    "    l = LabelEncoder()\n",
    "    data = l.fit_transform(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f24800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def covert_objects_to_int(data):\n",
    "    columns = data.columns\n",
    "    for i in columns:\n",
    "        if data[i].dtype == object:\n",
    "            data[i] = label_encoder(data[i])\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e6f19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "def model(loader_type,data,data_type,scaler_type,model_type,model_name,analysis_type,train_column_limit,classes,label,test_ratio=0.3):\n",
    "    data = loader(loader_type,data,axis=0,drop_index=True)\n",
    "    \n",
    "    #convert objects to int\n",
    "    rta_ = covert_objects_to_int(rta_)\n",
    "    \n",
    "    #column and label selection\n",
    "    rta_t,columns = select_train_columns(data,train_column_limit)\n",
    "    rta_label = select_label_column(data,label)\n",
    "\n",
    "    #spilting\n",
    "    rta_t_train_x1,rta_t_test_x1,rta_label_train_y1,rta_label_test_y1 = data_spliter(rta_t,rta_label,random_state=2,test_size=test_ratio)\n",
    "\n",
    "    #saving training and testing data\n",
    "    write_data(data_type,rta_t_train_x1,\"C:\\\\Users\\\\DIVINE\\\\Desktop\\\\assignment\\\\data\\\\train\\\\training_data\")\n",
    "    write_data(data_type,rta_t_test_x1,\"C:\\\\Users\\\\DIVINE\\\\Desktop\\\\assignment\\\\data\\\\test\\\\testing_data\")\n",
    "\n",
    "    #scaling\n",
    "    ss1_fit = scalers(scaler_type,rta_t_train_x1)\n",
    "    ss1_test = scalers(scaler_type,rta_t_test_x1)\n",
    "\n",
    "\n",
    "    #training of the model\n",
    "    model = train(model_type,rta_t_train_x1,rta_label_train_y1,model_name)\n",
    "\n",
    "    #predicting\n",
    "    preds = predict(model_name,ss1_test)\n",
    "\n",
    "    #evaluation\n",
    "    metrics = model_analysis(rta_label_test_y1,preds,classes,typ_=analysis_type)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf09965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "def prediction(data,model_name,scaler_type):\n",
    "    data = pd.Dataframe(data)\n",
    "    data = covert_objects_to_int(data)\n",
    "    data = scalers(scaler_type,data)\n",
    "    preds = predict(model_name,data)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f27af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retraining\n",
    "def retrained(train,label,test,test_label,classes,typ_,model_name,scaler_type):\n",
    "    model = retrain(typ_=typ_,model_name=model_name,train=train,label=label)\n",
    "    preds = model.predict(test)\n",
    "    #evaluation\n",
    "    metrics = model_analysis(true_labels=test_label,predicted_labels=preds,classes=classes,typ_=analysis_type) \n",
    "    return metrics\n",
    "\n",
    "def process(loader_type,train,label,train_column_limit,data_type,test_ratio=0.3):\n",
    "    train = loader(loader_type,train,axis=0,drop_index=True)\n",
    "    \n",
    "    #convert objects to int\n",
    "    train = covert_objects_to_int(train)\n",
    "    \n",
    "    #column and label selection\n",
    "    train,columns = select_train_columns(train,train_column_limit)\n",
    "    label = select_label_column(train,label)\n",
    "    \n",
    "    #spilting\n",
    "    train_x,test_x,label_x,test_y = data_spliter(train,label,random_state=2,test_size=test_ratio)\n",
    "\n",
    "    #saving training and testing data\n",
    "    write_data(data_type,train_x,\"C:\\\\Users\\\\DIVINE\\\\Desktop\\\\assignment\\\\data\\\\train\\\\training_data\")\n",
    "    write_data(data_type,test_x,\"C:\\\\Users\\\\DIVINE\\\\Desktop\\\\assignment\\\\data\\\\test\\\\testing_data\")\n",
    "\n",
    "    #scaling\n",
    "    scaled_train_x = scalers(scaler_type,train_x)\n",
    "    scaled_test_x = scalers(scaler_type,test_x)\n",
    "    return scaled_train_x,scaled_test_x,label_x,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24a063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"C:\\\\Users\\\\DIVINE\\\\Desktop\\\\assignment\\\\data\\\\train\\\\cleaned.csv\"\n",
    "rta = read_from_file_or_data(sect=\"file\",typ_=\"csv\",name=data,sep=\",\") \n",
    "rta_ = rta\n",
    "rta_ = covert_objects_to_int(rta_)\n",
    "rta_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c57424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Univariate Analysis\n",
    "rta_.hist(bins=15,edgecolor=\"blue\",color=\"red\",linewidth=1.0,xlabelsize=8,ylabelsize=8,grid=False)\n",
    "plt.tight_layout(rect=(0.0,0.0,1.2,1.2))\n",
    "plt.suptitle(\"Univariate\",x=0.6,y=1.3,fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d7b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MulitVariate Analyis\n",
    "fig,ax = plt.subplots(figsize=(20,10))\n",
    "rta_corr = rta_.corr()\n",
    "heatmap = sns.heatmap(round(rta_corr,2),ax=ax,annot=True,cmap=\"coolwarm\",fmt=\".2f\",linewidths=1.5)\n",
    "fig.subplots_adjust(top=0.95)\n",
    "t = fig.suptitle(\"Heat Map Of The Correlation\",y=1,fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d4a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
